"""import requests
from bs4 import BeautifulSoup

def get_newspapers_for_countries(countries):
    
    #Fetch the list of newspapers and their links for given countries from onlinenewspapers.com.
    #:param countries: List of country names.
    #:return: Dictionary with country names as keys and a list of newspapers (name and URL) as values.
    
    base_url = "https://onlinenewspapers.com"
    results = {}

    for country in countries:
        # Format the URL based on the country name
        country_slug = country.lower().replace(" ", "-")
        url = f"{base_url}/{country_slug}.shtml"
        
        try:
            # Fetch the page content
            response = requests.get(url)
            response.raise_for_status()  # Raise an exception for HTTP errors
            soup = BeautifulSoup(response.content, "html.parser")
            
            # Find all newspaper links (inside <li><a> elements)
            newspapers = []
            for li in soup.select("li a"):
                name = li.text.strip()
                link = li.get("href")
                if link and link.startswith("http"):  # Ensure valid links
                    newspapers.append({"name": name, "url": link})
            
            # Store results for the country
            results[country] = newspapers
        except requests.exceptions.RequestException as e:
            print(f"Error fetching data for {country}: {e}")
            results[country] = []

    return results

# Example usage
countries = ["Tunisia", "Mexico", "Morocco"]
newspapers = get_newspapers_for_countries(countries)

# Print results
for country, sources in newspapers.items():
    print(f"Newspapers for {country}:")
    for source in sources:
        print(f"- {source['name']}: {source['url']}")
    print()
"""
from transformers import AutoModelForCausalLM, AutoTokenizer

def get_news_sources(country):
    """
    Use BLOOM to generate a list of local news sources for a given country.
    :param country: Name of the country.
    :return: List of local news sources generated by BLOOM.
    """
    # Load BLOOM model and tokenizer
    model_name = "bigscience/bloom-3b"  # Smaller version for faster inference
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(model_name)

    # Prompt for BLOOM
    prompt = f"List the top local news sources in {country}. Include the name and website if possible."

    # Tokenize the input prompt
    inputs = tokenizer(prompt, return_tensors="pt")

    # Generate the output
    outputs = model.generate(
        inputs["input_ids"],
        max_length=200,  # Limit response length
        num_beams=5,     # Improve quality by considering multiple possibilities
        early_stopping=True
    )

    # Decode the generated text
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return response

# Example usage
countries = ["Tunisia", "Mexico", "Morocco"]
for country in countries:
    print(f"News sources for {country}:")
    result = get_news_sources(country)
    print(result)
    print()
